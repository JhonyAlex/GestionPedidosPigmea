# ğŸ” DiagnÃ³stico: Â¿Por QuÃ© Se Cae la Base de Datos?

## ğŸ“Š AnÃ¡lisis de Tus Logs

En los logs que compartiste vi esto:
```
2025-11-12T10:52:14.582Z SIGTERM received, shutting down gracefully
2025-11-12T10:52:14.583Z ğŸ”„ Cerrando conexiones a PostgreSQL...
2025-11-12T10:52:14.583Z âœ… Conexiones a PostgreSQL cerradas
```

**Esto NO es una caÃ­da de la BD**, es un **reinicio del backend** por Dokploy/Docker.

---

## ğŸš¨ Causas Comunes de "CaÃ­da" de BD

### 1. **Reinicio del Contenedor (Lo MÃ¡s ComÃºn)**

#### Â¿QuÃ© es SIGTERM?
- SeÃ±al de Docker/Kubernetes que indica: "ApÃ¡gate limpiamente"
- **NO significa** que la BD se cayÃ³
- **Significa** que Docker/Dokploy reiniciÃ³ el backend

#### Â¿Por quÃ© Dokploy reinicia el backend?

| Causa | SÃ­ntomas en Logs | SoluciÃ³n |
|-------|------------------|----------|
| **Health check falla** | `Health check timeout` antes del `SIGTERM` | Verificar que `/health` responde en < 30s |
| **Consume mucha RAM** | `OOMKilled` en logs de Docker | Aumentar lÃ­mite de memoria o optimizar cÃ³digo |
| **Deploy nuevo** | `SIGTERM` despuÃ©s de push a git | Normal - es el proceso de actualizaciÃ³n |
| **Crash del proceso** | Stack trace antes del `SIGTERM` | Revisar el error anterior |

#### CÃ³mo Verificar:
```bash
# Ver logs de Docker
docker logs backend-container --tail 100

# Ver por quÃ© se reiniciÃ³ el contenedor
docker inspect backend-container | grep -A 10 "State"
```

---

### 2. **BD PostgreSQL Se Cae (Menos ComÃºn)**

#### SeÃ±ales en los Logs:
```
âŒ ERROR EN POOL DE CONEXIONES: Connection terminated unexpectedly
   - CÃ³digo: ECONNREFUSED
   ğŸ”´ CAUSA: PostgreSQL no estÃ¡ corriendo o no es accesible
```

#### Causas Principales:

#### **2.1. PostgreSQL se quedÃ³ sin memoria**
```bash
# Ver logs de PostgreSQL
docker logs postgres-container --tail 50

# Buscar:
# - "out of memory"
# - "OOM killer"
# - "terminating connection due to administrator command"
```

**SoluciÃ³n**:
- Aumentar memoria del contenedor PostgreSQL
- Ajustar parÃ¡metros de PostgreSQL:
  ```sql
  -- Ver memoria configurada
  SHOW shared_buffers;
  SHOW work_mem;
  
  -- Optimizar si es necesario
  ALTER SYSTEM SET shared_buffers = '256MB';
  ALTER SYSTEM SET work_mem = '4MB';
  ```

---

#### **2.2. Demasiadas conexiones abiertas**
```
âŒ ERROR EN POOL DE CONEXIONES: sorry, too many clients already
   - CÃ³digo: 53300
   ğŸ”´ CAUSA: Demasiadas conexiones abiertas (max_connections alcanzado)
```

**SoluciÃ³n**:
```sql
-- Ver conexiones actuales
SELECT count(*) FROM pg_stat_activity;

-- Ver lÃ­mite
SHOW max_connections;

-- Ver quiÃ©n estÃ¡ usando conexiones
SELECT 
    datname, 
    usename, 
    count(*) 
FROM pg_stat_activity 
GROUP BY datname, usename;

-- Aumentar lÃ­mite (en postgresql.conf o variable de entorno)
ALTER SYSTEM SET max_connections = 200;
```

**En docker-compose.yml**:
```yaml
services:
  postgres:
    environment:
      POSTGRES_MAX_CONNECTIONS: 200
```

---

#### **2.3. Queries lentas bloqueando la BD**
```
âš ï¸ Pool de conexiones al 95% de capacidad
   - Total: 19/20
   - Idle: 0
   - Waiting: 15
```

**SoluciÃ³n**:
```sql
-- Ver queries lentas en ejecuciÃ³n
SELECT 
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query,
    state
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY duration DESC;

-- Matar query problemÃ¡tica
SELECT pg_terminate_backend(pid);

-- Configurar timeout para queries largas
ALTER DATABASE gestion_pedidos SET statement_timeout = '30s';
```

---

#### **2.4. Disco lleno**
```
âŒ ERROR EN POOL DE CONEXIONES: could not write to file: No space left on device
```

**SoluciÃ³n**:
```bash
# Ver espacio en disco
docker exec postgres-container df -h

# Limpiar logs antiguos de PostgreSQL
docker exec postgres-container sh -c "find /var/lib/postgresql/data/log -name '*.log' -mtime +7 -delete"

# En Dokploy, revisar volÃºmenes y aumentar si es necesario
```

---

### 3. **Problemas de Red (En la Nube)**

#### SeÃ±ales:
```
âŒ Health check fallÃ³: Health check timeout
   - CÃ³digo: ETIMEDOUT
   ğŸ”´ CAUSA: Timeout de conexiÃ³n (red lenta o PostgreSQL sobrecargado)
```

#### Causas:
- Latencia alta entre backend y PostgreSQL
- Firewall bloqueando puertos
- DNS no resolviendo correctamente

**SoluciÃ³n**:
```yaml
# docker-compose.yml - Asegurar que backend y postgres estÃ©n en la misma red
services:
  backend:
    networks:
      - app-network
    depends_on:
      - postgres
  
  postgres:
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

---

## ğŸ› ï¸ Nuevo Sistema de DiagnÃ³stico Implementado

He aÃ±adido **event listeners** al pool de conexiones que te dirÃ¡n exactamente quÃ© estÃ¡ pasando:

### Logs que VerÃ¡s Ahora:

#### âœ… Todo OK:
```
âœ… PostgreSQL conectado correctamente
   - Host: db
   - Database: gestion_pedidos
   - Max connections: 20
ğŸ‘‚ Event listeners del pool configurados
ğŸ”— Nueva conexiÃ³n al pool establecida
ğŸ”„ Health checks periÃ³dicos iniciados (cada 10s)
```

#### âš ï¸ Pool cerca del lÃ­mite:
```
âš ï¸ Pool de conexiones al 85% de capacidad
   - Total: 17/20
   - Idle: 2
   - Waiting: 3
```
**AcciÃ³n**: Investigar por quÃ© hay tantas conexiones abiertas.

#### âŒ Error de conexiÃ³n:
```
âŒ ERROR EN POOL DE CONEXIONES: Connection terminated
   - CÃ³digo: ECONNREFUSED
   - Timestamp: 2025-11-12T10:52:14.583Z
   ğŸ”´ CAUSA: PostgreSQL no estÃ¡ corriendo o no es accesible
ğŸš¨ PRODUCCIÃ“N: Marcando BD como no disponible debido a error
```

---

## ğŸ”§ ConfiguraciÃ³n Recomendada para ProducciÃ³n

### 1. **Variables de Entorno para PostgreSQL**

```bash
# En Dokploy / docker-compose.yml
POSTGRES_MAX_CONNECTIONS=100        # Aumentar de 20 a 100
POSTGRES_SHARED_BUFFERS=256MB       # Memoria para cache
POSTGRES_WORK_MEM=16MB              # Memoria por operaciÃ³n
POSTGRES_MAINTENANCE_WORK_MEM=64MB  # Para VACUUM, etc.
```

### 2. **Backend - Pool de Conexiones**

```javascript
// En postgres-client.js (ya configurado)
this.config = {
    max: 20,                      // MÃ¡ximo 20 conexiones por backend
    idleTimeoutMillis: 30000,     // Cerrar conexiones idle despuÃ©s de 30s
    connectionTimeoutMillis: 2000, // Timeout para obtener conexiÃ³n
};
```

### 3. **Monitoreo en Dokploy**

- **Health Check**: Configurar timeout de 10 segundos (no 5)
- **Memory Limit**: 
  - Backend: 512MB mÃ­nimo
  - PostgreSQL: 1GB mÃ­nimo
- **Restart Policy**: `unless-stopped` (reiniciar si se cae)

---

## ğŸ“ˆ Checklist de PrevenciÃ³n

### Diario:
- [ ] Revisar logs de backend para errores de pool
- [ ] Verificar que health check `/health` responde rÃ¡pido

### Semanal:
- [ ] Revisar uso de disco de PostgreSQL
- [ ] Ejecutar `VACUUM ANALYZE` en tablas grandes
- [ ] Revisar queries lentas:
  ```sql
  SELECT * FROM pg_stat_statements 
  ORDER BY mean_exec_time DESC 
  LIMIT 10;
  ```

### Mensual:
- [ ] Aumentar lÃ­mites si el sistema crece
- [ ] Revisar Ã­ndices faltantes
- [ ] Analizar patrones de uso de conexiones

---

## ğŸš€ Comandos Ãštiles

### Ver Estado de PostgreSQL:
```bash
# Conectar a PostgreSQL
docker exec -it postgres-container psql -U pigmea_user -d gestion_pedidos

# Ver conexiones activas
SELECT count(*), state FROM pg_stat_activity GROUP BY state;

# Ver tamaÃ±o de BD
SELECT pg_size_pretty(pg_database_size('gestion_pedidos'));

# Ver tablas mÃ¡s grandes
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;
```

### Ver Logs del Backend:
```bash
# Ãšltimas 100 lÃ­neas
docker logs backend-container --tail 100

# Seguir logs en tiempo real
docker logs backend-container -f

# Filtrar errores de BD
docker logs backend-container 2>&1 | grep -i "pool\|postgresql\|database"
```

### Ver Logs de PostgreSQL:
```bash
# Ver logs
docker logs postgres-container --tail 50

# Buscar errores
docker logs postgres-container 2>&1 | grep -i "error\|fatal\|panic"
```

---

## ğŸ¯ Â¿QuÃ© Dice "BD no inicializada" Ahora?

**ANTES** (confuso):
```
âš ï¸ BD no inicializada
âš ï¸ Usando autenticaciÃ³n de headers (modo desarrollo)
```
ğŸ‘‰ No sabes si es problema real o modo desarrollo

**AHORA** (claro):

En **ProducciÃ³n**:
```
âŒ ERROR EN POOL DE CONEXIONES: connection refused
   - CÃ³digo: ECONNREFUSED
   ğŸ”´ CAUSA: PostgreSQL no estÃ¡ corriendo o no es accesible
ğŸš¨ PRODUCCIÃ“N: Marcando BD como no disponible debido a error
```
ğŸ‘‰ Sabes exactamente quÃ© pasÃ³ y por quÃ©

En **Desarrollo**:
```
âš ï¸ DESARROLLO: Usando autenticaciÃ³n de desarrollo (sin BD)
```
ğŸ‘‰ EstÃ¡ claro que es modo desarrollo

---

## ğŸ’¡ Resumen: Â¿Por QuÃ© Se CayÃ³ en Tu Caso?

BasÃ¡ndome en tus logs:
```
2025-11-12T10:52:14.582Z SIGTERM received, shutting down gracefully
```

**ConclusiÃ³n**: El backend se reiniciÃ³, probablemente por:
1. **Deploy nuevo** en Dokploy (normal)
2. **Health check fallÃ³** (revisar timeout)
3. **Consumo excesivo de memoria** (revisar lÃ­mites)

**NO fue una caÃ­da de PostgreSQL**, sino un reinicio controlado del backend.

---

## ğŸ“ PrÃ³ximos Pasos

1. **Monitorear logs** con los nuevos event listeners
2. **Si ves `âŒ ERROR EN POOL`**, seguir las soluciones especÃ­ficas de arriba
3. **Configurar alertas** en Dokploy para:
   - Health check failures
   - High memory usage
   - Container restarts

---

**Ãšltima ActualizaciÃ³n**: 12 de noviembre de 2025  
**Autor**: GitHub Copilot
